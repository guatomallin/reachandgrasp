{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#% What do we use to determine the beginning and end of a reach?\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Micro questions related to this process.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x8e in position 4: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 23>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m files:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m#read csv\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \n\u001B[0;32m     26\u001B[0m     \u001B[38;5;66;03m#We're going to have to avoid hidden files with an if statement\u001B[39;00m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m---> 28\u001B[0m         csv \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mD:/project_deeplabcut/r&d_cam3_2D-CP-2021-07-19/videos/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m         csv \u001B[38;5;241m=\u001B[39m Multi_indexer\u001B[38;5;241m.\u001B[39mMultiIndexMaker(csv)\n\u001B[0;32m     33\u001B[0m         csv_complete \u001B[38;5;241m=\u001B[39mMulti_indexer\u001B[38;5;241m.\u001B[39mrexsearch(file, csv)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1231\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1228\u001B[0m     f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n\u001B[0;32m   1230\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1231\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmapping\u001B[49m\u001B[43m[\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1232\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001B[0m, in \u001B[0;36mCParserWrapper.__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     72\u001B[0m     kwds\u001B[38;5;241m.\u001B[39mpop(key, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     74\u001B[0m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m ensure_dtype_objs(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m---> 75\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader \u001B[38;5;241m=\u001B[39m \u001B[43mparsers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTextReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munnamed_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reader\u001B[38;5;241m.\u001B[39munnamed_cols\n\u001B[0;32m     79\u001B[0m \u001B[38;5;66;03m# error: Cannot determine type of 'names'\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:544\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:633\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._get_header\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\DEEPLABCUT\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1952\u001B[0m, in \u001B[0;36mpandas._libs.parsers.raise_parser_error\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0x8e in position 4: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from preprocessing.classes import FilterandThresholds, simpleKinematics\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sympy  import *\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "#import xarray as xr\n",
    "velocityChancla = simpleKinematics('tester')\n",
    "curvePeaks = simpleKinematics('multi_reach')\n",
    "splitter = FilterandThresholds('Tester single reach')\n",
    "Multi_indexer = FilterandThresholds('MultiIndex')\n",
    "\n",
    "path = r'D:/project_deeplabcut/r&d_cam3_2D-CP-2021-07-19/videos'\n",
    "files = [file for file in os.listdir(path)]\n",
    "\n",
    "multi_reach= pd.DataFrame()\n",
    "csvs_animalNum = []\n",
    "#This section of the code coverts each CSV file into a multiindex dataframe. Then it searches the title of each CSV files\n",
    "#... to extract animal condition, the number of the reach limb used, and light condition, and whether the reach failed or succeeded.\n",
    "#... then concatenantes reach CSV and adds variables extracted from the title into a giant dataframe,\n",
    "for file in files:\n",
    "    #read csv\n",
    "\n",
    "    #We're going to have to avoid hidden files with an if statement\n",
    "    if not file.startswith('.'):\n",
    "        csv = pd.read_csv('D:/project_deeplabcut/r&d_cam3_2D-CP-2021-07-19/videos/' + file)\n",
    "\n",
    "\n",
    "        csv = Multi_indexer.MultiIndexMaker(csv)\n",
    "\n",
    "        csv_complete =Multi_indexer.rexsearch(file, csv)\n",
    "\n",
    "        multi_reach = pd.concat([multi_reach, csv_complete], ignore_index = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Provisional data upload method\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#We should add the ability to filter predictions- in this case accurate tracking isnt imperative.\n",
    "\n",
    "\n",
    "bodypartSelector = FilterandThresholds('TestingThis')\n",
    "\n",
    "Platform = bodypartSelector.bodypart_selector(multi_reach, 'Platform', likelihoodSelect=True)\n",
    "plt.plot(Platform['y'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Select bodypart\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Slit = bodypartSelector.bodypart_selector(multi_reach, 'Platform', likelihoodSelect=True)\n",
    "plt.plot(Slit['Time'], Slit['x'])\n",
    "\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#LIMB LEFT ANALYSIS\n",
    "\n",
    "#Try one\n",
    "WristL = bodypartSelector.bodypart_selector(multi_reach, 'WristL' , likelihoodSelect=True)\n",
    "\n",
    "#We should choose only those reaches that are of left reach.\n",
    "WristL = WristL[WristL['Limb'] == 'left']\n",
    "print(WristL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#FROM HERE FORWARD THIS COLLECTS REACHES AND SIMPLE KINEMATICS- this can be made into classes.\n",
    "#Group dataframe by reach and number\n",
    "WristLbyReach = WristL.groupby(['Reach Number', 'ID'])\n",
    "keys = WristLbyReach.groups.keys()\n",
    "x =[]\n",
    "reaches = []\n",
    "for key in keys:\n",
    "    reach = WristLbyReach['x'].get_group(key)\n",
    "    Time =  WristLbyReach.get_group(key)\n",
    "    reaches.append(reach)\n",
    "    x.append(x)\n",
    "    #print(reaches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Now we're iterating throught he groups.\n",
    "constantAccVelocity = pd.DataFrame()\n",
    "WristLExtendCleaned = pd.DataFrame()\n",
    "cleanedData = pd.DataFrame()\n",
    "listit = np.arange(100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "#Initiate the simple kinematic dataframes and lists\n",
    "\n",
    "#Cleaned data frames initialization\n",
    "Cleanedduration_Frame = pd.DataFrame()\n",
    "duration_Frame = pd.DataFrame()\n",
    "Cleanedduration = []\n",
    "CleanedstrikeNum = []\n",
    "CleanedIDnum = []\n",
    "CleanedvelocityAvg = []\n",
    "cleanCondition = []\n",
    "cleanPerformance = []\n",
    "\n",
    "#Dirty data frames initialization\n",
    "duration = []\n",
    "strikeNum = []\n",
    "IDnum = []\n",
    "velocityAvg = []\n",
    "Condition = []\n",
    "performance =[]\n",
    "\n",
    "\n",
    "for reach, ID in WristLbyReach:\n",
    "    ID = pd.DataFrame(ID)\n",
    "    #Calculate the raw velocity and store in dataframe -\n",
    "\n",
    "    #What if we smooth the ID plot - see how it works...\n",
    "\n",
    "    ID['smoothed_x'] = gaussian_filter1d(ID['x'], sigma = 2)\n",
    "    minX = np.argmin(ID['smoothed_x'])\n",
    "\n",
    "    velocity = velocityChancla.velocity(ID[: minX], 'smoothed_x')\n",
    "    conditionStr = ID['Condition'].iloc[1]\n",
    "    performanceStr = ID['performance'].iloc[1]\n",
    "\n",
    "\n",
    "\n",
    "    #We need to make a peak velocity peak selector - a blanket does not work because the velocity peak max are variable.\n",
    "    if velocity.size > 0:\n",
    "        maxPeak = max(velocity)\n",
    "        minPeak = min(velocity)\n",
    "        peakHeight_tochoose = round(maxPeak/10)\n",
    "        troughHeight_tochoose = abs(round(minPeak))\n",
    "        #print(peakHeight_tochoose)\n",
    "        #print(troughHeight_tochoose)\n",
    "    else:\n",
    "        peakHeight_tochoose = 1\n",
    "\n",
    "    trough_output_velocity, peak_output_velocity, min_indy, velocity, promineneces_velocity = curvePeaks.curveExtractor(velocity, trough_height=1000, trough_width=None, peak_height=peakHeight_tochoose, peak_width=None, prominences=5, gausFilter=False)\n",
    "    #print(peak_output_velocity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #We need to concatenate all signals\n",
    "    Cleaned, ExtendCleaned, minIndex = splitter.splitter(signal=ID, velocity_peaks=peak_output_velocity, whichPlane='x' )\n",
    "    strike, IDNum = reach\n",
    "\n",
    "    fig, axs = plt.subplots(3)\n",
    "    fig.suptitle('Comparison to Velocity')\n",
    "    axs[0].plot(velocity[:minIndex])\n",
    "    axs[1].plot(ExtendCleaned['x'])\n",
    "    axs[2].plot(Cleaned['x'])\n",
    "    axs[1].invert_yaxis()\n",
    "    axs[2].invert_yaxis()\n",
    "    axs[0].plot(peak_output_velocity, velocity[peak_output_velocity], \"x\")\n",
    "    axs[0].plot(np.zeros_like(velocity), \"--\", color=\"gray\")\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(reach)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if len(Cleaned) != len(np.arange(0, (0.003 * len(Cleaned)), 0.003)):\n",
    "        print('no len match on cleaned')\n",
    "        Cleaned = Cleaned.iloc[2: , :]\n",
    "        Cleaned['Time_Aligned'] = np.arange(0, (0.003 * len(Cleaned)), 0.003)\n",
    "        #add x_vals\n",
    "\n",
    "        Cleaned['x_vals'] = np.arange(0, len(Cleaned), 1)\n",
    "\n",
    "        CleanedforVel = Cleaned[['x', 'y', 'Time_Aligned']]\n",
    "        diff = CleanedforVel.diff()\n",
    "        coords = [c for c in CleanedforVel if not 'Time_Aligned' in c]\n",
    "        Cleaned['Velocity'] = np.linalg.norm(diff[coords], axis =1)/diff['Time_Aligned']\n",
    "\n",
    "        Avgvelocity = np.linalg.norm(CleanedforVel[coords].iloc[-1]-CleanedforVel[coords].iloc[0])/(CleanedforVel['Time_Aligned'].iloc[-1] - CleanedforVel['Time_Aligned'].iloc[0])\n",
    "\n",
    "\n",
    "        #Calculate duration\n",
    "        Cleanedduration.append(CleanedforVel['Time_Aligned'].iloc[-1] - CleanedforVel['Time_Aligned'].iloc[0])\n",
    "        CleanedstrikeNum.append(int(strike))\n",
    "        CleanedIDnum.append(IDNum)\n",
    "        CleanedvelocityAvg.append(Avgvelocity)\n",
    "        cleanCondition.append(conditionStr)\n",
    "        cleanPerformance.append(performanceStr)\n",
    "        #Calculate average velocity\n",
    "    else:\n",
    "        Cleaned['Time_Aligned'] = np.arange(0, (0.003 * len(Cleaned)), 0.003)\n",
    "        Cleaned['x_vals'] = np.arange(0, len(Cleaned), 1)\n",
    "\n",
    "        CleanedstrikeNum.append(int(strike))\n",
    "        CleanedIDnum.append(IDNum)\n",
    "\n",
    "        CleanedforVel = Cleaned[['x', 'y', 'Time_Aligned']]\n",
    "        diff = CleanedforVel.diff()\n",
    "        coords = [c for c in CleanedforVel if not 'Time_Aligned' in c]\n",
    "        Cleaned['Velocity'] = np.linalg.norm(diff[coords], axis =1)/diff['Time_Aligned']\n",
    "\n",
    "        Avgvelocity = np.linalg.norm(CleanedforVel[coords].iloc[-1]-CleanedforVel[coords].iloc[0])/(CleanedforVel['Time_Aligned'].iloc[-1] - CleanedforVel['Time_Aligned'].iloc[0])\n",
    "        Cleanedduration.append(CleanedforVel['Time_Aligned'].iloc[-1] - CleanedforVel['Time_Aligned'].iloc[0])\n",
    "        CleanedvelocityAvg.append(Avgvelocity)\n",
    "        cleanCondition.append(conditionStr)\n",
    "        cleanPerformance.append(performanceStr)\n",
    "    if len(ExtendCleaned) != (0.003 * len(ExtendCleaned)):\n",
    "        print('no len match on Extend')\n",
    "        ExtendCleaned = ExtendCleaned.iloc[2: , :]\n",
    "        #print(len(ExtendCleaned))\n",
    "        ExtendCleaned['Time_Aligned'] = np.arange(0, (3 * len(ExtendCleaned)), 3)\n",
    "        ExtendCleaned['x_vals'] = np.arange(0, len(ExtendCleaned), 1)\n",
    "\n",
    "        ExtendCleanedforVel = ExtendCleaned[['x', 'y', 'Time_Aligned']]\n",
    "        diff = ExtendCleanedforVel.diff()\n",
    "        coords = [c for c in ExtendCleanedforVel if not 'Time_Aligned' in c]\n",
    "        #print(CleanedforVel)\n",
    "        ExtendCleaned['Velocity'] = np.linalg.norm(diff[coords], axis =1)/diff['Time_Aligned']\n",
    "\n",
    "        duration.append(ExtendCleaned['Time_Aligned'].iloc[-1])\n",
    "\n",
    "\n",
    "\n",
    "        Avgvelocity = np.linalg.norm(ExtendCleanedforVel[coords].iloc[-1]-ExtendCleanedforVel[coords].iloc[0])/ExtendCleanedforVel['Time_Aligned'].iloc[-1] - ExtendCleanedforVel['Time_Aligned'].iloc[0]\n",
    "\n",
    "        strikeNum.append(int(strike))\n",
    "        IDnum.append(IDNum)\n",
    "        velocityAvg.append(Avgvelocity)\n",
    "        Condition.append(conditionStr)\n",
    "        performance.append(performanceStr)\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "        ExtendCleaned['Time_Aligned'] = np.arange(0, (0.003* len(ExtendCleaned)), 0.003)\n",
    "        ExtendCleaned['x_vals'] = np.arange(0, len(ExtendCleaned), 1)\n",
    "\n",
    "        ExtendCleanedforVel = ExtendCleaned[['x', 'y', 'Time_Aligned']]\n",
    "        diff = ExtendCleanedforVel.diff()\n",
    "        coords = [c for c in ExtendCleanedforVel if not 'Time_Aligned' in c]\n",
    "\n",
    "        ExtendCleaned['Velocity'] = np.linalg.norm(diff[coords], axis =1)/diff['Time_Aligned']\n",
    "        print('no len match on Extend')\n",
    "        duration.append(ExtendCleaned['Time_Aligned'].iloc[-1])\n",
    "        strikeNum.append(int(strike))\n",
    "        IDnum.append(IDNum)\n",
    "\n",
    "        xr.align(ExtendCleaned['x'], ExtendCleaned['y'])\n",
    "\n",
    "\n",
    "        Avgvelocity = np.linalg.norm(ExtendCleanedforVel[coords].iloc[-1]-ExtendCleanedforVel[coords].iloc[0], axis=1)/(WristLExtendCleaned['Time_Aligned'].iloc[-1] - WristLExtendCleaned['Time_Aligned'].iloc[0])\n",
    "\n",
    "        velocityAvg.append(Avgvelocity)\n",
    "        Condition.append(conditionStr)\n",
    "        performance.append(performanceStr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cleanedData = pd.concat([cleanedData, Cleaned], ignore_index=True)\n",
    "    WristLExtendCleaned = pd.concat([WristLExtendCleaned, ExtendCleaned], ignore_index=True)\n",
    "duration_Frame['duration'] = duration\n",
    "duration_Frame['Strike'] = strikeNum\n",
    "duration_Frame['ID'] = IDnum\n",
    "duration_Frame['AvgVelocity'] = velocityAvg\n",
    "duration_Frame['Condition'] = Condition\n",
    "duration_Frame['peformance'] = performance\n",
    "\n",
    "Cleanedduration_Frame['duration'] = Cleanedduration\n",
    "Cleanedduration_Frame['Strike'] = strikeNum\n",
    "Cleanedduration_Frame['ID'] = IDnum\n",
    "Cleanedduration_Frame['AvgVelocity'] = CleanedvelocityAvg\n",
    "Cleanedduration_Frame['Condition'] = cleanCondition\n",
    "Cleanedduration_Frame['performance'] = cleanPerformance\n",
    "\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8), dpi = 80)\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.lineplot(x = 'Time_Aligned', y = 'y', hue = 'Condition', data = cleanedData)\n",
    "plt.xlabel('Time (ms)', fontsize=22)\n",
    "plt.ylabel('Left Forepaw Vertical Displacement (mm))', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 22)\n",
    "ax.invert_yaxis()\n",
    "plt.title('Vertical Displacement over Time ', fontsize=25)\n",
    "plt.legend(loc=1, prop={'size': 19})\n",
    "#fig.savefig('/Users/carlospineda/Desktop/TEMP Mono Reaching Code Dev/path_y_time.svg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(WristLExtendCleaned)\n",
    "fig = plt.figure(figsize=(10, 8), dpi = 80)\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.lineplot(x = 'Time_Aligned', y = 'x', hue = 'Condition',data = cleanedData)\n",
    "plt.xlabel('Time (ms)', fontsize=22)\n",
    "plt.ylabel('Left Forepaw Horizontal Displacement (mm)', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 22)\n",
    "ax.invert_yaxis()\n",
    "plt.title('Horizontal Displacement over Time ', fontsize=25)\n",
    "plt.legend(loc=1, prop={'size': 19})\n",
    "\n",
    "#fig.savefig('/Users/carlospineda/Desktop/TEMP Mono Reaching Code Dev/path_x_Time.svg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X-Y Plot - non-aligned\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8), dpi = 80)\n",
    "Cleaned['x'] = gaussian_filter1d(Cleaned['x'], sigma = 2)\n",
    "Cleaned['y'] = gaussian_filter1d(Cleaned['y'], sigma = 2)\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.lineplot(x = 'x', y = 'y', hue = 'Condition', data = cleanedData)\n",
    "plt.xlabel('Frame', fontsize=20)\n",
    "plt.ylabel('Left Forepaw Vertical Displacement (mm)', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "ax.invert_yaxis()\n",
    "plt.title('X-Y Plot - non aligned  ', fontsize=25)\n",
    "plt.legend(loc=1, prop={'size': 25})\n",
    "#fig.savefig('/Users/carlospineda/Desktop/TEMP Mono Reaching Code Dev/path_unshifted.svg')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8), dpi = 80)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.lineplot(x = 'Time_Aligned', y = 'Velocity', hue = 'Condition',data = WristLExtendCleaned)\n",
    "plt.xlabel('Time (ms)', fontsize=20)\n",
    "plt.ylabel('Velocity (mm/s)', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "plt.title('Velocity over time', fontsize=25)\n",
    "plt.legend(loc=1, prop={'size': 25})\n",
    "#fig.savefig('/Users/carlospineda/Desktop/TEMP Mono Reaching Code Dev/AggregateVelocity.svg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8), dpi= 80)\n",
    "p = sns.boxplot(x='Condition', y='AvgVelocity', data=Cleanedduration_Frame)\n",
    "\n",
    "\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "\n",
    "p.set_xlabel(\"Condition\", fontsize = 22)\n",
    "p.set_ylabel(\"Mean Velocity (mm/s)\", fontsize = 22)\n",
    "sns.set(font_scale = 2)\n",
    "plt.ylim(0, 1000)\n",
    "plt.title('Mean Velocity', fontsize=25)\n",
    "plt.ylim()\n",
    "plt.show()\n",
    "fig.savefig('/Users/carlospineda/Desktop/TEMP Mono Reaching Code Dev/Average Velocity.svg')\n",
    "# positions = [0, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8), dpi = 80)\n",
    "#sns.set(style=\"darkgrid\")\n",
    "p=sns.boxplot(x=\"Condition\", y=\"duration\", data=Cleanedduration_Frame)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "\n",
    "sns.set(font_scale = 3)\n",
    "# Decoration\n",
    "p.set_xlabel(\"Condition\", fontsize = 22)\n",
    "p.set_ylabel(\"Duration (s)\", fontsize = 22)\n",
    "p.get_xticklabels()\n",
    "plt.title('Mean Duration', fontsize=25)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "fig.savefig('/Users/carlospineda/Desktop/TEMP Mono Reaching Code Dev/Average Duration.svg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Stats\n",
    "import scipy.stats as ss\n",
    "values_per_group = [col for col_name, col in Cleanedduration_Frame.groupby('Condition')['duration']]\n",
    "ss.ranksums(*values_per_group)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "values_per_group = [col for col_name, col in Cleanedduration_Frame.groupby('Condition')['AvgVelocity']]\n",
    "ss.ranksums(*values_per_group)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Fast fourier transform filter\n",
    "reachSample = cleanedData[cleanedData['Reach Number'] == '1']\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.scatterplot(x = 'x', y = 'y', hue = 'Condition', style='ID', data = reachSample)\n",
    "plt.xlabel('Horizontal Position (mm)', fontsize=20)\n",
    "plt.ylabel('vertical position (mm)', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()\n",
    "plt.legend(loc='upper left', prop={'size': 19})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%Check reaches\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reachSample = cleanedData[cleanedData['Reach Number'] == '16']\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.lineplot(x = 'x', y = 'y', hue = 'Condition', style='ID', data = reachSample)\n",
    "plt.xlabel('Horizontal Position (mm)', fontsize=20)\n",
    "plt.ylabel('vertical position (mm)', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()\n",
    "plt.legend(loc='upper left', prop={'size': 19})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reachSampleExtend = WristLExtendCleaned[WristLExtendCleaned['Reach Number'] == '2']\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.scatterplot(x = 'x', y = 'y', hue = 'Condition', style='ID', data = reachSampleExtend)\n",
    "plt.xlabel('Horizontal Position (mm)', fontsize=20)\n",
    "plt.ylabel('vertical position (mm)', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()\n",
    "plt.legend(loc='upper left', prop={'size': 19})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Check Reaches\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reachSampleExtend = WristLExtendCleaned[WristLExtendCleaned['Reach Number'] == '2']\n",
    "plt.rcParams['figure.figsize'] = (20, 7)\n",
    "my_pal = {'blind' : 'mediumblue', 'control':'crimson'}\n",
    "ax = sns.lineplot(x = 'x', y = 'y', hue = 'Condition', style='ID', data = reachSampleExtend)\n",
    "plt.xlabel('Horizontal Position (mm)', fontsize=20)\n",
    "plt.ylabel('vertical position (mm)', fontsize=20)\n",
    "plt.tick_params(axis = 'both', which = 'major', labelsize = 20)\n",
    "ax.invert_yaxis()\n",
    "ax.invert_xaxis()\n",
    "plt.legend(loc='upper left', prop={'size': 19})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cleanedData['ConditionDummy'] = np.where(cleanedData['Condition'] == \"blind\", 1, 0)\n",
    "\n",
    "\n",
    "ax1 = plt.gca( projection='3d')\n",
    "pnt3D = ax1.scatter(cleanedData['x'],cleanedData['Time_Aligned'],cleanedData['y'], c =cleanedData['ConditionDummy'] ,cmap='seismic')\n",
    "#ax1.plot(x, y, z, color = 'b')\n",
    "#pnt3d_slit = ax1.scatter(x_slit, y_slit, z_slit)\n",
    "#pnt3d_selbow=ax1.scatter(x_elbow,y_elbow, z_elbow)\n",
    "plt.colorbar(pnt3D)\n",
    "#pnt3d_platform = ax1.scatter(x_platform, y_platform, z_platform)\n",
    "#pnt3d_elbow = ax1.scatter(x_elbow, y_elbow, z_elbow)\n",
    "plt.gca().invert_zaxis()\n",
    "#plt.gca().invert_yaxis()\n",
    "#Figure out how to plot this rightside up.\n",
    "\n",
    "#Figure out how to plot this rightside up.\n",
    "\n",
    "#cbar = plt.colorbar()\n",
    "#cbar = plt.colorbar(pnt3d_elbow)\n",
    "#cbar = plt.colorbar(pnt3d_platform)\n",
    "# ax1.plot([210, 210], [5,15], [243,243], color='black')\n",
    "# ax1.plot([220, 220], [11, 11], [210,243], color = 'black')\n",
    "# ax1.plot([220, 220], [8, 8], [210,243], color = 'black')\n",
    "# ax1.plot([210, 220], [5, 5], [243,243], color = 'black')\n",
    "# ax1.plot([210, 220], [15,15], [243,243], color = 'black')\n",
    "# ax1.plot([220, 220], [5, 15], [243,243], color = 'black')\n",
    "# ax1.plot([220, 220], [8, 11], [210,210], color = 'black')\n",
    "# ax1.plot([5, 5], [2.75, 2.75], [-4,-3], color = 'black')\n",
    "# ax1.plot([5, 5], [1.50, 1.50], [-4,-3], color = 'black')\n",
    "# ax1.plot([5, 5], [1, 1], [-4,-3], color = 'black')\n",
    "# ax1.plot([5, 5], [3, 3], [-4,-3], color = 'black')\n",
    "# ax1.plot([5, 5], [1, 1.75], [-3,-3], color='black')\n",
    "# ax1.plot([5, 5], [1, 3], [-4,-4], color = 'black')\n",
    "\n",
    "ax1.set_xlabel('Horizontal Displacement', fontsize = 15)\n",
    "ax1.set_zlabel('Vertical Displacement)', fontsize = 15)\n",
    "ax1.set_ylabel('Time (ms)', fontsize = 15)\n",
    "# plt.xticks(fontsize = 16)\n",
    "# plt.yticks(fontsize = 16)\n",
    "# plt.zticks(fontsize = 16)\n",
    "ax1.tick_params(axis='both', which='major', labelsize=6)\n",
    "ax1.tick_params(axis='both', which='minor', labelsize=6)\n",
    "#fig.suptitle('Forepaw Trajectory in 3D', fontsize=24)\n",
    "#ax1.view_init(0, 60)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TESTING\n",
    "\n",
    "#CALCULATING TANGENTIAL/INSTANT VELOCITY\n",
    "\n",
    "#Use a single curve for this 11094 control reach 1\n",
    "reachSample = cleanedData[cleanedData['Reach Number'] == '1']\n",
    "\n",
    "print(reachSample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%Alternative way of calculating tangential velocity\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}